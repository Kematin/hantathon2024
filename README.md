<p align="center">
  <a href="https://gitlab.hackathon.uriit.ru/kematin2/11">
    <img src="images/robot.png" alt="ассистент" width="200px" height="200px"/>
  </a>
</p>

<h1 align="center">
  Голосовой ассистент
</h1>


<div align="center">
Голосовой ассистент для людей маломобильной группы населения, с возможностью классификации команд засчет обученной NLP-модели.

**Специально для хакатона [*-Югорский Хантатон 2024-*](https://хантатон.рф/2024/)**
</div>

***

## Над проектом работали
- Павленко Ольга Павловна (дизайнер)
- Агишев Рафаэль Ринатович (Fullstack - разработчик)
- Голощапов Максим Сергеевич (Fullstack - разработчик)

## Запуск и Технологии

Для установки, тестирования и запуска: **[installation.md](docs/installation.md)**

Основные технологии:
- Python3.12
- FastAPI
- Utils
    - Poetry
    - Loguru
    - Pydantic
- Libs
    - gTTS
    - faster-whisper
    - transformers
    - torch
- AI
    - Whisper (speech2text)
    - Custom classifier
    - Google Text2Speech

Вся логика frontend части описана в **[index.js](src/component/js/index.js)**

## Обучение NLP Модели

Посмотреть процесс обучения локальной модели можно в **[train.md](docs/train.md)**

***
## Архитектура проекта
![[images/schema.png]]
> Бэкенд, занимается обработкой полученного с фронта голоса
> - сначала переводит его в текст (Whisper)
> - потом определяют заложенную в нем команду с помощью специально обученной нейросети ([train.md](docs/train.md))

>Фронтенд, занимается записью голоса и отправкой его на бэк, после получения команды, исполняет ее.

## Использование голосового ассистента 
Голосовой ассистента доступен в разделе "Тематическая карта", для его использования необходимо нажать на кнопку "ассистент"
![[images/hmao_map.jpg]]

***

## Кейс

_[Все Кейсы](https://hackathon.uriit.ru/2024/tasks/)_

11 кейс - "Голосовой ассистент для карты «Доступность объектов для инвалидов и маломобильных групп населения» ТИС Югры"

